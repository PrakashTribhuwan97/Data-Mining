# -*- coding: utf-8 -*-
"""CA2_Data_Mining_Prakash_SMS (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ABF6aIp6BGqRwI4b5DuWpRA-Qt8E7pkv

# **Data Preparation**:
"""

import re, nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('omw-1.4')
nltk.download('wordnet')
# Download the missing 'punkt_tab' resource
nltk.download('punkt_tab') # This line is added to download the necessary resource
import numpy as np
import pandas as pd
from bs4 import BeautifulSoup
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import StratifiedKFold
from sklearn import metrics
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import MultinomialNB
import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import plotly.graph_objs as go
import plotly.figure_factory as ff
import umap # use 'pip install umap-learn' or 'conda install -c conda-forge umap-learn'
import umap # use 'pip install umap-learn' or 'conda install -c conda-forge umap-learn'

pip install umap-learn

from google.colab import drive
drive.mount('/content/drive')

dataset = pd.read_csv("/content/SMSSpamCollection (1)", sep='\t', header=None, names=['label', 'message'])
print(dataset.head())

print(dataset.shape)

print(dataset.info())

print(dataset.describe())

# Dividing dataset into label and feature sets
X = dataset.drop(['label'], axis = 1) # Features
Y = dataset['label'] # Labels
print(type(X))
print(type(Y))

print(X.shape)
print(Y.shape)

# Reading Dataset

file_name = "/content/SMSSpamCollection (1)"

import pandas as pd
file_name = "/content/SMSSpamCollection (1)"

# Use read_csv with the appropriate delimiter and names
df = pd.read_csv(file_name, encoding='latin-1', sep='\t', header=None, names=['label', 'message'])

# Display the DataFrame
display(df)

pd.set_option('display.max_colwidth', None) # Setting this so we can see the full content of cells
pd.set_option('display.max_columns', None) # to make sure we can see all the columns in output window

# Cleaning messages
def cleaner(message):
    soup = BeautifulSoup(message, 'lxml') # removing HTML entities such as â€˜&ampâ€™,â€™&quotâ€™,'&gt'; lxml is the html parser and shoulp be installed using 'pip install lxml'
    souped = soup.get_text()
    re1 = re.sub(r"(@|http://|https://|www|\\x)\S*", " ", souped) # substituting @mentions, urls, etc with whitespace
    re2 = re.sub("[^A-Za-z]+"," ", re1) # substituting any non-alphabetic character that repeats one or more times with whitespace
    tokens = nltk.word_tokenize(re2)
    lower_case = [t.lower() for t in tokens]
    stop_words = set(stopwords.words('english'))
    filtered_result = list(filter(lambda l: l not in stop_words, lower_case))
    wordnet_lemmatizer = WordNetLemmatizer()
    lemmas = [wordnet_lemmatizer.lemmatize(t,'v') for t in filtered_result]
    return lemmas

df['cleaned_message'] = df.message.apply(cleaner)
df = df[df['cleaned_message'].map(len) > 0] # removing rows with cleaned summaries of length 0
print("Printing top 5 rows of dataframe showing original and cleaned messages....")
print(df[['message','cleaned_message']].head())
df['cleaned_message'] = [" ".join(row) for row in df['cleaned_message'].values] # joining tokens to create strings. TfidfVectorizer does not accept tokens as input
data = df['cleaned_message']
Y = df['label'] # target column
tfidf = TfidfVectorizer(min_df=0.0062, ngram_range=(1,3)) # min_df=.0062 means that each ngram (unigram, bigram, & trigram) must be present in at least 30 documents for it to be considered as a token (4825*.0062=~30). This is a clever way of feature engineering
tfidf.fit(data) # learn vocabulary of entire data
data_tfidf = tfidf.transform(data) # creating tfidf values
pd.DataFrame(pd.Series(tfidf.get_feature_names_out())).to_csv('Vocabulary_messages.csv', header=False, index=False)
print("Shape of tfidf matrix: ", data_tfidf.shape)

print("Implementing SVC.....")
# Implementing Support Vector Classifier
svc_clf = LinearSVC() # kernel = 'linear' and C = 1

"""#**Balancing the Data using Undersampling**"""

import pandas as pd

# Load the dataset
df = pd.read_csv("SMSSpamCollection (1)", sep='\t', header=None, names=['label', 'message'])

# Check original class distribution
print("Original class distribution:")
print(df['label'].value_counts())

# Separate spam and ham
ham = df[df['label'] == 'ham']
spam = df[df['label'] == 'spam']

# Randomly undersample the majority class (ham)
ham_undersampled = ham.sample(n=len(spam), random_state=42)

# Combine undersampled ham with all spam
df_balanced = pd.concat([ham_undersampled, spam], axis=0)

# Shuffle the balanced dataset
df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)

# Check new class distribution
print("\nBalanced class distribution:")
print(df_balanced['label'].value_counts())

from imblearn.over_sampling import SMOTE

"""## **Implementing PCA to visualize dataset**"""

# Dividing dataset into label and feature sets
X = dataset[['message']]  # Features - Select the 'message' column for tf-idf
Y = dataset['label'] # Labels

# Previous code using TF-IDF to convert messages to numerical features


# Assuming 'data_tfidf' is your TF-IDF matrix, use that for scaling
feature_scaler = StandardScaler()
X_scaled = feature_scaler.fit_transform(data_tfidf.toarray()) # Convert sparse to dense

pca = PCA(n_components =2)
pca.fit(X_scaled)
x_pca = pca.transform(X_scaled)
print("Variance explained by each of the n_components: ",pca.explained_variance_ratio_)
print("Total variance explained by the n_components: ",sum(pca.explained_variance_ratio_))

# Assuming 'dataset' is your DataFrame and 'Y' contains the labels
# Create a LabelEncoder object
label_encoder = LabelEncoder()

# Fit the encoder to your labels and transform them into numerical values
Y_encoded = label_encoder.fit_transform(Y)

# Now use 'Y_encoded' for the 'color' argument in your go.Scatter call
digits = list(dataset['label'])
data = [go.Scatter(x=x_pca[:, 0], y=x_pca[:, 1], mode='markers',
                    marker=dict(color=Y_encoded, colorscale='Rainbow', opacity=0.5),
                    text=[f'digit: {a}' for a in digits],
                    hoverinfo='text')]

layout = go.Layout(title = 'PCA Dimensionality Reduction', width = 700, height = 700,
                    xaxis = dict(title='First Principal Component'),
                    yaxis = dict(title='Second Principal Component'))
fig = go.Figure(data=data, layout=layout)
fig.show()

"""## **Implementing UMAP to visualize dataset**

*   List item
*   List item


"""

u = umap.UMAP(n_components = 2, n_neighbors=15, min_dist=0.1)
x_umap = u.fit_transform(X_scaled)

# Assuming 'dataset' is your DataFrame and 'Y' contains the labels
# Create a LabelEncoder object
label_encoder = LabelEncoder()

# Fit the encoder to your labels and transform them into numerical values
Y_encoded = label_encoder.fit_transform(Y)

# Now use 'Y_encoded' for the 'color' argument in your go.Scatter call
digits = list(dataset['label'])
data = [go.Scatter(x=x_umap[:, 0], y=x_umap[:, 1], mode='markers',
                    marker=dict(color=Y_encoded, colorscale='Rainbow', opacity=0.5),
                    text=[f'digit: {a}' for a in digits],
                    hoverinfo='text')]

layout = go.Layout(title = 'UMAP Dimensionality Reduction', width = 700, height = 700,
                    xaxis = dict(title='First Dimension'),
                    yaxis = dict(title='Second Dimension'))
fig = go.Figure(data=data, layout=layout)
fig.show()

# Resetting index to make sure they match
# Assuming df was overwritten, recreate 'cleaned_message' if it doesn't exist
if 'cleaned_message' not in df.columns:
    df['cleaned_message'] = df.message.apply(cleaner)  # Assuming 'cleaner' function is defined

df = df[df['cleaned_message'].map(len) > 0].reset_index(drop=True)

# TF-IDF features
data = df['cleaned_message']
# Convert the list of words back into a single string for each message
data = data.apply(lambda x: ' '.join(x) if isinstance(x, list) else x)
tfidf = TfidfVectorizer(min_df=0.0062, ngram_range=(1,3))
tfidf.fit(data)
data_tfidf = tfidf.transform(data)

"""# **Model Creation and Evaluation**

# **Implementing Support Vector Classifier**

---
"""

# Running cross-validation
kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1) # 10-fold cross-validation


# Resetting index to make sure they match
# Assuming df was overwritten, recreate 'cleaned_message' if it doesn't exist
if 'cleaned_message' not in df.columns:
    df['cleaned_message'] = df.message.apply(cleaner)  # Assuming 'cleaner' function is defined

df = df[df['cleaned_message'].map(len) > 0].reset_index(drop=True)

# ***Update Y to match the filtered DataFrame***
Y = df['label'].reset_index(drop=True)  # Reset index to align with data_tfidf

# TF-IDF features
data = df['cleaned_message']
# Convert the list of words back into a single string for each message
data = data.apply(lambda x: ' '.join(x) if isinstance(x, list) else x)
tfidf = TfidfVectorizer(min_df=0.0062, ngram_range=(1,3))
tfidf.fit(data)
data_tfidf = tfidf.transform(data)

scores=[] # This will store all scores
p = []  # This will store precision scores
a = []  # This will store accuracy scores
r = []  # This will store recall scores
f1 = [] # This will store f1 scores
iteration = 0
smote=SMOTE(random_state=101)
for train_index, test_index in kf.split(data_tfidf, Y):
    iteration += 1
    print("Iteration ", iteration)
    X_train, Y_train = data_tfidf[train_index], Y.iloc[train_index]
    X_test, Y_test = data_tfidf[test_index], Y.iloc[test_index]
    X_train,Y_train=smote.fit_resample(X_train,Y_train)
    svc_clf.fit(X_train, Y_train) # Fitting SVC
    Y_pred = svc_clf.predict(X_test)
    precision_score = metrics.precision_score(Y_test, Y_pred, pos_label='spam') # Calculating accuracy
    accuracy_score = metrics.accuracy_score(Y_test, Y_pred)
    recall_score = metrics.recall_score(Y_test, Y_pred, pos_label='spam')
    f1_score = metrics.f1_score(Y_test, Y_pred, pos_label='spam')
    print("Cross-validation precision: ", precision_score)
    print("Cross-validation accuracy: ", accuracy_score)
    print("Cross-validation recall: ", recall_score)
    print("Cross-validation f1 score: ", f1_score)

    p.append(precision_score) # appending cross-validation precision for each iteration
    a.append(accuracy_score)
    r.append(recall_score)
    f1.append(f1_score)
svc_mean_precision = np.mean(p)
svc_mean_accuracy = np.mean(a)
svc_mean_recall = np.mean(r)
svc_mean_f1 = np.mean(f1)

# ***Update Y to match the filtered DataFrame***
Y = df['label'].reset_index(drop=True)  # Reset index to align with data_tfidf
# Averages
print("\f--- Mean Scores ---")
print("Mean Precision: ", svc_mean_precision)
print("Mean Accuracy: ", svc_mean_accuracy)
print("Mean Recall: ", svc_mean_recall)
print("Mean F1 Score: ", svc_mean_f1)

"""# **Hyperparameter Tuning for Linear SVC**"""

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, chi2

Y = df['label'].reset_index(drop=True)  # Reset index to match cleaned messages

data = df['cleaned_message'].reset_index(drop=True)
data = df['cleaned_message'].reset_index(drop=True)
# Convert the list of words back into a single string for each message
data = data.apply(lambda x: ' '.join(x) if isinstance(x, list) else x) # This line is the change
data_tfidf = tfidf.fit_transform(data)

# Ensure both features and labels match in length
data = df['cleaned_message'].reset_index(drop=True)
Y = df['label'].reset_index(drop=True)

# Ensure 'data' contains strings instead of lists
data = df['cleaned_message'].reset_index(drop=True)
data = data.apply(lambda x: ' '.join(x) if isinstance(x, list) else x)  # Join tokens into strings

# Recreate TF-IDF matrix
tfidf = TfidfVectorizer(min_df=0.0062, ngram_range=(1,3))
tfidf.fit(data)
data_tfidf = tfidf.transform(data)

from sklearn.pipeline import Pipeline
from sklearn.feature_selection import SelectKBest, chi2

# Define pipeline
svc_pipeline = Pipeline([
    ('feature_selection', SelectKBest(chi2)),
    ('classifier', LinearSVC())
])

# Define parameter grid
svc_param_grid = {
    'feature_selection__k': [1000, 2000, 'all'],
    'classifier__C': [0.01, 0.1, 1, 10],
    'classifier__max_iter': [1000, 5000, 10000]
}
# GridSearchCV with StratifiedKFold
svc_grid = GridSearchCV(svc_pipeline, param_grid=svc_param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=1)
svc_grid.fit(data_tfidf, Y)

from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.feature_selection import SelectKBest, chi2

print("Running GridSearchCV for LinearSVC...")

# Define pipeline
svc_pipeline = Pipeline([
    ('feature_selection', SelectKBest(chi2)),
    ('classifier', LinearSVC())
])

# Define parameter grid
svc_param_grid = {
    'feature_selection__k': [1000, 2000, 'all'],
    'classifier__C': [0.01, 0.1, 1, 10],
    'classifier__max_iter': [1000, 5000, 10000]
}

# GridSearchCV with StratifiedKFold
svc_grid = GridSearchCV(svc_pipeline, param_grid=svc_param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=1)

# Fit on data
svc_grid.fit(data_tfidf, Y)

print("\nBest Parameters for LinearSVC:")
print(svc_grid.best_params_)

print("Best F1 Score for LinearSVC: ", svc_grid.best_score_)

"""# **Implementing Multinomial Naive Bayes Classifier**

"""

print("Implementing NBC.....")
# Implementing Naive Bayes Classifier
nbc_clf = MultinomialNB()

import imblearn
from imblearn.over_sampling import SMOTE

# Running cross-validation
kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=1) # 10-fold cross-validation
scores=[]
p = []  # This will store precision scores
a = []  # This will store accuracy scores
r = []  # This will store recall scores
f1 = [] # This will store f1 scores
iteration = 0
smote=SMOTE(random_state=101)
for train_index, test_index in kf.split(data_tfidf, Y):
    iteration += 1
    print("Iteration ", iteration)
    X_train, Y_train = data_tfidf[train_index], Y.iloc[train_index]
    X_test, Y_test = data_tfidf[test_index], Y.iloc[test_index]
    X_train,Y_train=smote.fit_resample(X_train,Y_train)
    nbc_clf.fit(X_train, Y_train) # Fitting NBC
    Y_pred = nbc_clf.predict(X_test)
    precision_score = metrics.precision_score(Y_test, Y_pred, pos_label='spam') # Calculating accuracy
    accuracy_score = metrics.accuracy_score(Y_test, Y_pred)
    recall_score = metrics.recall_score(Y_test, Y_pred, pos_label='spam')
    f1_score = metrics.f1_score(Y_test, Y_pred, pos_label='spam')
    print("Cross-validation precision: ", precision_score)
    print("Cross-validation accuracy: ", accuracy_score)
    print("Cross-validation recall: ", recall_score)
    print("Cross-validation f1 score: ", f1_score)

    p.append(precision_score) # appending cross-validation precision for each iteration
    a.append(accuracy_score)
    r.append(recall_score)
    f1.append(f1_score)
nbc_mean_precision = np.mean(p)
nbc_mean_accuracy = np.mean(a)
nbc_mean_recall = np.mean(r)
nbc_mean_f1 = np.mean(f1)

# Averages
print("\f--- Mean Scores ---")
print("Mean Precision: ", nbc_mean_precision)
print("Mean Accuracy: ", nbc_mean_accuracy)
print("Mean Recall: ", nbc_mean_recall)
print("Mean F1 Score: ", nbc_mean_f1)

"""# **Hyperparameter Tuning for MultinomialNB**

*   List item
*   List item



"""

print("\nRunning GridSearchCV for MultinomialNB...")

# Define pipeline
nb_pipeline = Pipeline([
    ('feature_selection', SelectKBest(chi2)),
    ('classifier', MultinomialNB())
])

# Define parameter grid
nb_param_grid = {
    'feature_selection__k': [1000, 2000, 'all'],
    'classifier__alpha': [0.001, 0.01, 0.1, 1, 10]
}

# GridSearchCV with StratifiedKFold
nb_grid = GridSearchCV(nb_pipeline, param_grid=nb_param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=1)

# Fit on data
nb_grid.fit(data_tfidf, Y)

print("\nBest Parameters for MultinomialNB:")
print(nb_grid.best_params_)

print("Best F1 Score for MultinomialNB: ", nb_grid.best_score_)

"""# **Best Model Comparison**

"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Assuming svc_grid and nb_grid are from previous cells
svc_best_model = svc_grid.best_estimator_  # Get the best model from GridSearchCV for SVC
nb_best_model = nb_grid.best_estimator_  # Get the best model from GridSearchCV for NB
# Make predictions

svc_preds = svc_best_model.predict(data_tfidf)
nb_preds = nb_best_model.predict(data_tfidf)


# Define a function to calculate metrics
def evaluate_model(name, y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, pos_label='spam')
    rec = recall_score(y_true, y_pred, pos_label='spam')
    f1 = f1_score(y_true, y_pred, pos_label='spam')
    print(f"\nðŸ” Performance of {name}:")
    print(f"Accuracy:  {acc:.4f}")
    print(f"Precision: {prec:.4f}")
    print(f"Recall:    {rec:.4f}")
    print(f"F1 Score:  {f1:.4f}")
    return {"Model": name, "Accuracy": acc, "Precision": prec, "Recall": rec, "F1": f1}

# Evaluate both models
svc_results = evaluate_model("LinearSVC", Y, svc_preds)
nb_results = evaluate_model("MultinomialNB", Y, nb_preds)

# Compare side-by-side in DataFrame
comparison_df = pd.DataFrame([svc_results, nb_results])
print("\nðŸ“Š Model Comparison Table:")
print(comparison_df)

# Choose best model based on F1 Score
best_model_name = svc_results["Model"] if svc_results["F1"] > nb_results["F1"] else nb_results["Model"]
print(f"\nâœ… Best Model Overall: {best_model_name}")

"""# **Confusion Matrix**"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt # Import matplotlib for plotting

# Final best models from tuning (if not already done)
svc_best_model = svc_grid.best_estimator_
nb_best_model = nb_grid.best_estimator_

# Predictions on full data using 'data_tfidf' instead of 'X_tfidf'
svc_preds = svc_best_model.predict(data_tfidf)
nb_preds = nb_best_model.predict(data_tfidf)

# Confusion matrices
svc_cm = confusion_matrix(Y, svc_preds, labels=["ham", "spam"])
nb_cm = confusion_matrix(Y, nb_preds, labels=["ham", "spam"])

# Plot LinearSVC Confusion Matrix
disp_svc = ConfusionMatrixDisplay(confusion_matrix=svc_cm, display_labels=["ham", "spam"])
disp_svc.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix - LinearSVC")
plt.show()

# Plot MultinomialNB Confusion Matrix
disp_nb = ConfusionMatrixDisplay(confusion_matrix=nb_cm, display_labels=["ham", "spam"])
disp_nb.plot(cmap=plt.cm.Oranges)
plt.title("Confusion Matrix - MultinomialNB")
plt.show()

print("LinearSVC Confusion Matrix:\n", svc_cm)
print("MultinomialNB Confusion Matrix:\n", nb_cm)